[package]
name = "minarrow"
version = "0.7.4"
edition = "2024"
authors = ['Peter G. Bower']
build = "build.rs"
license = "MIT"
readme = "README.md"
repository = "https://github.com/pbower/minarrow"
documentation = "https://docs.rs/minarrow/"
keywords = [
    "arrow",
    "apache-arrow",
    "polars",
    "data",
    "simd",
]
categories = ["data-structures", "science", "parsing", "external-ffi-bindings"]
description = "Apache Arrow-compatible, Rust-first columnar data library for high-performance computing, native streaming, and embedded workloads. Minimal dependencies, ultra-low-latency access, automatic 64-byte SIMD alignment, and fast compile times. Great for real-time analytics, HPC pipelines, and systems integration."
# All of the below external dependencies do not need to be enabled directly
# See [features] for the relevant feature that enables them.
[dependencies]

# Arrow and Polars are for optional to/from_apache_arrow() and to/from_polars() via the optional
# `cast_arrow` and `cast_polars` features.
arrow = { version = "55.2.0", default-features = false, features = [
    "ffi",
    "prettyprint",
], optional = true }
arrow-schema = { version = "55.2.0", features = ["ffi"], optional = true }
polars = { version = "0.50.0", features = [
    # Core needed for Series/DataFrame
    "lazy",
    "dtype-categorical",
    "dtype-date",
    "dtype-datetime",
    "dtype-time",
    "dtype-struct",
    "dtype-decimal",
    "performant",
    "fmt",
], optional = true }
polars-arrow = { version = "0.50.0", optional = true }
time = { version = "0.3", optional = true, features = ["parsing", "formatting", "macros", "local-offset"] }
phf = { version = "0.11", features = ["macros"], optional = true }
num-traits = "0.2.19"
rayon = { version = "1.10.0", optional = true }
snappy = { version = "0.4.0", optional = true }
zstd = { version = "0.13.3", optional = true }
ryu = { version = "1.0.20", optional = true }
memchr = { version = "2.7.5", optional = true }
ahash = { version = "0.8.12", optional = true }
regex = { version = "1.11.1", optional = true }
vec64 = { version = "0.2.1"}

[build-dependencies]
cc = { version = "1", optional = true }

[target.'cfg(target_os = "linux")'.dependencies]
libc = "0.2"

[features]

# Adds parallel iterators via `Rayon`
parallel_proc = ["rayon"]

# Adds roundtrip FFI tests. Leave off if you don't need it
# in your build pipeline, as it's mostly C-code.
c_ffi_tests = ['cc']

# Adds Categorical8, Categorical16, and Categorical64.
#
# Highly recommend keeping these off unless required
# E.g., constrained or embedded environments, as they add combinatorial
# weight to the binary and enum match arms
extended_categorical = ["extended_numeric_types"]

# Adds UInt8, UInt16, Int8, Int16 types.
#
# Highly recommend keeping these off unless required
# E.g., constrained or embedded environments, as they add combinatorial
# weight to the binary and enum match arms.
#
# For most analytical use cases, they get upcasted anyway.
extended_numeric_types = []

# Adds a cube object for stacking tables on an extra axis
# Useful for time series, and group analytics
cube = []

# Adds a unified scalar type, that's useful for `Array` aggregations, and other use cases where you end up with one value.
# However, it is one of several downcasting methods available in Rust, and when predominantly
# working with numbers, one might prefer using `my_function::<i32>()` semantics which addresses
# the type immediately, e.g., in conjunction with `T: Numeric`, `T: Integer` or `T:Float` generic functions,
# rather than getting a `Scalar` object make that then needs `.i32()` style access, or a manual match.
# It is a pain that Rust can't just get the value when it's wrapped in such cases, but this is an inherent type safety limitation.
scalar_type = []

# Adds a unified value enum, that can be used for engine-level orchestration or any situation
# where a catch-all, unified encompassing type is required to satisfy the compiler.
# It includes roundtrip `From` and `TryFrom` for each inner type so that signatures do
# not need to couple to it directly. Recommend leaving off if you don't need it.
value_type = []

# `ChunkedArray` and `ChunkedTable` objects that support iterating
# over multiple inner objects of the same type, for memory-mapped streaming etc.
chunked = []

# Int64-based string
large_string = []

# Provides windowed collection views for Numeric, String, and Temporal types.
# Often, everything can be done with only the `ArrayView` abstraction, or,
# the `ArrayViewT` (&Array, Offset, Length) tuple from aliases.
# These are for the cases where they fall short, e.g., you
# have numeric or text specific functions, and want to streamline type management.
# In those cases, these abstractions provide the equivalent of `Into<NumericArrayView>`
# for several types, and accept both the original and windowed view variants. Therefore,
# one can unify numeric entry points through here enabling a flexible API, at the cost
# of more surface complexity.
views = []

# Adds a 2D matrix that uses a flat buffer in the format compatible with BLAS and LAPACK Fortan and C kernels.
# Includes `TryFrom` conversion methods so it's easy to move from `Table` column selections into the matrix,
# without worrying too much about buffers and strides. Hence, if you are working *only* with matrices, you may want
# this from the get-go. If you are working predominantly with Tabular data but running PCA's and SVD's (for e.g.),
# you can keep your data in Table format and any functions that accept `Matrix` should also work for your `Table`,
# with a small once-off performance penalty of cloning the columns into a contiguous buffer, that becomes noticeable
# with large data sizes.
matrix = []

# Adds the zstd compression option for Parquet and IPC formats
# Zstd offers a higher compression ratio but is slightly slower.
zstd = ["dep:zstd"]

# Adds the snappy compression option for Parquet and IPC format.
# Snappy is lightweight, minimal, but with less compression than zstd.
snappy = ["dep:snappy"]

# Adds `to_apache_arrow()` for casting into that library.
cast_arrow = ["arrow", "arrow-schema"]

# Adds `to_polars()` for casting into that library.
cast_polars = ["polars", "polars-arrow", "large_string"]

# Adds `Datetime` array types.
datetime = []

# Adds SIMD for the Bitmask and Arithmetic kernels
# A much more extensive set of kernels is available under the downstream simd-kernels crate.
simd = []

# Adds full datetime functionality with the `time` crate including:
# - Human-readable datetime conversions
# - Timezone-aware operations
# - Date/time arithmetic (add/subtract durations, dates)
# - Comparison operations
# - Component extraction (year, month, day, hour, etc.)
# At, the expense of an external dependency.
#
# Without this feature, datetime values are raw integer offsets.
# The `ArrowType` stored in `Field` and/or `FieldArray` specifies the
# logical type (Date32, Date64, Timestamp, etc.) for Arrow FFI compatibility.
datetime_ops = ["dep:time", "dep:phf", "datetime"]

# Adds string arithmetic kernels
# Includes (small) external dependencies, and supports
# str concatenation with floats for the arithmetic kernels
# e.g., "Hello" + 1.0 = "Hello1", etc.
# Also overloads std::ops::Add, Mul, Sub, Div, Pow
# with best-case String equivalents (e.g., '+' concatenates),
# for type unification rather than panicking.
str_arithmetic = ["ryu", "memchr"]

# Replaces all hashmaps and hashsets used for count distinct operations
# and categorical dictionary interning with the faster ahash.
fast_hash = ["dep:ahash"]

# Adds typed arithmetic broadcasting for add, sub, mult, div, rem
broadcast = []

# Adds byte size trait for best-effort size calculation
size = []

# Enables `arr[i]` indexing on MaskedArray types via Index<usize>.
#
# Without this feature, use `.get(i)` for null-safe access returning Option<T>,
# or `.get_raw(i)` for direct buffer access bypassing null checks.
#
# The Index trait does not check null masks, so enabling this on nullable arrays
# will silently return raw buffer values for null elements. Enable if you
# understand the implications and prefer the ergonomic `[]` syntax.
unchecked_index = []

# Adds pandas-style selection for Table and TableV with .c() and .r() methods
select = []

# Enables memfd-backed buffers for zero-copy cross-process sharing (Linux only).
# Use `MemfdBuffer::new()` to create a buffer, then pass the fd to child processes.
# Children call `MemfdBuffer::reopen()` to access the same physical memory.
memfd = []

default = [
    "views",
    "chunked",
    "large_string",
    "simd",
    "select",
]

[package.metadata.cargo-all-features]

# All optional dependencies have semnatic names
skip_optional_dependencies = true

# The maximum number of features to try at once
max_combination_size = 2

[package.metadata.docs.rs]
all-features = true
rustdoc-args = ["--cfg", "docsrs"]

# Arithmetic example
[[example]]
name = "arithmetic"
path = "examples/arithmetic.rs"
required-features = ["broadcast"]

# Broadcasting examples
[[example]]
name = "test_broadcasting"
path = "examples/broadcasting/test_broadcasting.rs"
required-features = ["broadcast"]

[[example]]
name = "test_scalar_arithmetic"
path = "examples/broadcasting/test_scalar_arithmetic.rs"
required-features = ["broadcast", "scalar_type"]

[[example]]
name = "test_string_broadcasting"
path = "examples/broadcasting/test_string_broadcasting.rs"
required-features = ["broadcast"]

[[example]]
name = "test_value_ops"
path = "examples/broadcasting/test_value_ops.rs"
required-features = ["broadcast"]

[[example]]
name = "test_value_macros"
path = "examples/broadcasting/test_value_macros.rs"
required-features = ["broadcast"]

# Benchmark examples
[[example]]
name = "hotloop_benchmark_simd"
path = "examples/benchmarks/hotloop_benchmark_simd.rs"

[[example]]
name = "hotloop_benchmark_std"
path = "examples/benchmarks/hotloop_benchmark_std.rs"

[[example]]
name = "hotloop_benchmark_avg_simd"
path = "examples/benchmarks/hotloop_benchmark_avg_simd.rs"

[[example]]
name = "hotloop_benchmark_avg_std"
path = "examples/benchmarks/hotloop_benchmark_avg_std.rs"

[[example]]
name = "benchmark_parallel_simd"
path = "examples/benchmarks/benchmark_parallel_simd.rs"

# FFI examples
[[example]]
name = "apache_arrow_ffi"
path = "examples/ffi/apache_arrow_ffi.rs"

[[example]]
name = "polars_ffi"
path = "examples/ffi/polars_ffi.rs"

# Print examples
[[example]]
name = "print_arrays"
path = "examples/print/print_arrays.rs"

[[example]]
name = "print_table"
path = "examples/print/print_table.rs"

# Selection example
[[example]]
name = "selection"
path = "examples/selection.rs"
required-features = ["select", "views"]

# Selection test
[[test]]
name = "test_selection"
path = "tests/test_selection.rs"
required-features = ["select", "views"]
